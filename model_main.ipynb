{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: alabaster==0.7.12 in c:\\users\\herringtoncm\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 1)) (0.7.12)\n",
      "Requirement already satisfied: anaconda-client==1.7.2 in c:\\users\\herringtoncm\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 2)) (1.7.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement anaconda-navigator==1.9.7\n",
      "ERROR: No matching distribution found for anaconda-navigator==1.9.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: interpolation in c:\\users\\herringtoncm\\anaconda3\\lib\\site-packages (2.2.1)\n",
      "Requirement already satisfied: numba>=0.47 in c:\\users\\herringtoncm\\anaconda3\\lib\\site-packages (from interpolation) (0.53.1)\n",
      "Requirement already satisfied: tempita>=0.5.2 in c:\\users\\herringtoncm\\anaconda3\\lib\\site-packages (from interpolation) (0.5.2)\n",
      "Requirement already satisfied: numpy>=1.18.1 in c:\\users\\herringtoncm\\anaconda3\\lib\\site-packages (from interpolation) (1.20.1)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\herringtoncm\\anaconda3\\lib\\site-packages (from interpolation) (1.6.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\herringtoncm\\anaconda3\\lib\\site-packages (from numba>=0.47->interpolation) (52.0.0.post20210125)\n",
      "Requirement already satisfied: llvmlite<0.37,>=0.36.0rc1 in c:\\users\\herringtoncm\\anaconda3\\lib\\site-packages (from numba>=0.47->interpolation) (0.36.0)\n",
      "\n",
      "nρ =  0 , ρ =  0.01\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-d4277c7b503d>:129: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return vr**0.5, vr_PS**0.5\n",
      "<ipython-input-1-d4277c7b503d>:129: RuntimeWarning: invalid value encountered in sqrt\n",
      "  return vr**0.5, vr_PS**0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "nρ =  1 , ρ =  0.7\n",
      "\n",
      "\n",
      "nρ =  2 , ρ =  -0.9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt\n",
    "!pip install interpolation \n",
    "from interpolation.splines import UCGrid, eval_linear  # see, https://github.com/EconForge/interpolation.py\n",
    "import numpy as np\n",
    "from numba import jit, njit\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import norm, gumbel_l\n",
    "import pandas as pd\n",
    "import csv\n",
    "from copy import deepcopy\n",
    "\n",
    "# Cell with jit-ted functions that cannot be called from within a class.\n",
    "\n",
    "@njit\n",
    "def c_life(whn, T, R, J):\n",
    " \n",
    "    return ((1 - R**(-1)) / (1 - R**(-J))) * T + whn\n",
    "\n",
    "@njit\n",
    "def y_life(whn, T, R, J):\n",
    "\n",
    "    return T + whn * ((1 - R**(-J)) / (1 - R**(-1)))\n",
    "\n",
    "@njit\n",
    "def foc_c_n(n, wh, T, R, J, ψ, ε, σ):\n",
    "    cmin = 1e-5\n",
    "    c = c_life(wh * n, T, R, J)\n",
    "    c = np.where(c>cmin, c, cmin)\n",
    "    foc = wh * du_dc(c, σ) + du_dn(1.0 - n, ψ, ε)\n",
    "    return foc\n",
    "\n",
    "@njit\n",
    "def solve_c_n(wh, T, R, J, ψ, ε, σ):\n",
    "    Err, I = 1e-9, 10\n",
    "    n_lo = np.zeros(len(wh)) \n",
    "    n_hi = np.ones(len(wh)) \n",
    "    foc_max, i = Err + 1, 0  \n",
    "    \n",
    "    # Iterate over guesses of n until foc is satisfied\n",
    "    while foc_max>Err and i<I:\n",
    "        n = (n_lo + n_hi) / 2\n",
    "        \n",
    "        foc = foc_c_n(n, wh, T, R, J, ψ, ε, σ)\n",
    "        n_lo = np.where(foc<-Err, n_lo, n)\n",
    "        n_hi = np.where(foc>Err, n_hi, n)\n",
    "        foc_max = np.amax(np.abs(foc))\n",
    "        i += 1   \n",
    "    c = c_life(wh * n, T, R, J)\n",
    "    \n",
    "    return c, n\n",
    "\n",
    "@njit\n",
    "def util(c, leis, σ, ψ, ε):\n",
    "    uc = (c**(1 - σ) - 1) / (1 - σ)\n",
    "    un = (ψ / (1 - ε)) * leis**(1-ε)\n",
    "    return uc + un\n",
    "\n",
    "@njit\n",
    "def du_dc(c, σ):\n",
    "    \"\"\"\n",
    "    Derivative of utility function wrt consumption.\n",
    "    \"\"\"\n",
    "    return c**(-σ)\n",
    "\n",
    "@njit\n",
    "def du_dn(leis, ψ, ε):\n",
    "    \"\"\"\n",
    "    Derivative of utility function wrt labor.\n",
    "    \"\"\"\n",
    "    return - ψ * leis**(-ε)\n",
    "\n",
    "@njit\n",
    "def γ(h, π1, π2):\n",
    "    h_bounded = np.maximum(np.minimum(h, 800), 200)\n",
    "    denom = 1 + np.exp(-(π1 + π2 * h_bounded))\n",
    "    return 1 / denom\n",
    "\n",
    "@njit\n",
    "def v_life(leis, whn, T, J, σ, ψ, ε, β, R):\n",
    "    y = y_life(whn, T, R, J)\n",
    "    c = c_life(whn, T, R, J)\n",
    "    u = util(c, leis, σ, ψ, ε)\n",
    "    return u * (1 - β**J) / (1 - β)\n",
    "\n",
    "@njit\n",
    "def vc_life(w_g, w_ng, n_a_g, n_a_ng, T, h, π1, π2, σ, ψ, ε, β, R, J):\n",
    "    # Compute value function from attending college prior to realization of grad vs. no grad\n",
    "    y_a_g = y_life(w_g * h * n_a_g, T, R, J)\n",
    "    y_a_ng = y_life(w_ng * h * n_a_ng, T, R, J)\n",
    "    \n",
    "    c_a_g = c_life(w_g * h * n_a_g, T, R, J)\n",
    "    c_a_ng = c_life(w_g * h * n_a_g, T, R, J)\n",
    "    \n",
    "    v_g = v_life(1.0 - n_a_g, w_g * h * n_a_g, T, J, σ, ψ, ε, β, R)\n",
    "    v_ng = v_life(1.0 - n_a_ng, w_ng * h * n_a_ng, T, J, σ, ψ, ε, β, R)\n",
    "    \n",
    "    return γ(h, π1, π2) * v_g + (1 - γ(h, π1, π2)) * v_ng\n",
    "\n",
    "# Cell with jit-ted functions that cannot be called from within a class.\n",
    "@njit\n",
    "def m_given_i(τi, τm, i, wH, n, θm, ρ):\n",
    "    # Derive elasticity of substitution\n",
    "    ε_mi = 1 / (1 - ρ)    \n",
    "    \n",
    "    # Derive optimal market investment given time investment\n",
    "    return  n * i * ( ((wH - τi) / (1 - τm)) * (θm / (1 - θm)) )**ε_mi\n",
    "\n",
    "@njit\n",
    "def hc(h, ni, m, a, H, θm, ρ, ϕ, ζ):\n",
    "    return 300.0 + a * ((H / 500)**ζ) * (θm * m**ρ + (1 - θm) * ni**ρ)**(ϕ/ ρ)\n",
    "\n",
    "def cov(x, y, w):\n",
    "    \"\"\"Weighted Covariance\"\"\"\n",
    "    return np.sum(w * (x - np.average(x, weights=w)) * (y - np.average(y, weights=w))) / np.sum(w)\n",
    "\n",
    "def corr(x, y, w):\n",
    "    \"\"\"Weighted Correlation\"\"\"\n",
    "    return cov(x, y, w) / np.sqrt(cov(x, x, w) * cov(y, y, w))\n",
    "\n",
    "def sd_weighted(v, λsp, λ):\n",
    "    mn_PS, vr_PS = np.zeros([2, 2]), np.zeros([2, 2])\n",
    "    for nP in range(2):\n",
    "        for nS in range(2):\n",
    "            v_PS, λ_PS = v[nP, nS, :, :], λ[nP, nS, :, :]\n",
    "            mn_PS = np.average(v_PS, weights=λ_PS)\n",
    "            vr_PS[nP, nS] = np.average((v_PS - mn_PS)**2, weights=λ_PS)\n",
    "    mn = np.average(v, weights=λ)\n",
    "    vr = np.average((v - mn)**2, weights=λ)\n",
    "    return vr**0.5, vr_PS**0.5\n",
    "\n",
    "@njit\n",
    "def gen_popwgts(λ, λsp, λH, λa, NP, NS, NH, Na):\n",
    "    for nP in range(NP):\n",
    "        for S in range(NS):\n",
    "            for nH in range(NH):\n",
    "                for na in range(Na):\n",
    "                    λ[nP, S, nH, na] = λsp[nP, S] * λH[nH] * λa[nP, S, na]\n",
    "    return λ / np.sum(λ)\n",
    "\n",
    "@njit\n",
    "def solve_n(w, p, inv, coh, σ, ψ, ε, minc):\n",
    "    Err, I = 1e-9, 10\n",
    "    n_lo = 0.0 \n",
    "    n_hi = p - inv \n",
    "    foc, i = Err + 1, 0  \n",
    "    \n",
    "    # Iterate over guesses of n until foc is satisfied\n",
    "    while np.abs(foc)>Err and i<I:\n",
    "        n = (n_lo + n_hi) / 2\n",
    "        \n",
    "        # Compute marginal cost of working\n",
    "        focR = du_dn(p - inv - n, ψ, ε)        \n",
    "        \n",
    "        # Compute marginal benefit of working\n",
    "        inc = w * n + coh\n",
    "        c = max(minc, inc)\n",
    "        focL = w * du_dc(c, σ)  \n",
    "        \n",
    "        # Evaluate foc and update bounds on savings policy\n",
    "        foc = focL + focR             \n",
    "        n_lo = n_lo * (foc<-Err) + n * (foc>=-Err)\n",
    "        n_hi = n * (foc<=Err) + n_hi * (foc>Err) \n",
    "        i += 1\n",
    "    \n",
    "    if np.abs(foc)>10*Err:\n",
    "        'solve_n: ERROR! FOC violated. n=', np.round(n, 3), ', c=', np.round(c, 3), ', foc=', np.round(foc, 5)\n",
    "    \n",
    "    return c, n\n",
    "\n",
    "@njit\n",
    "def solve_kk(w, p, inv, m, gridk_interp, gridcc, R, β, σ, ψ, ε, minc):\n",
    "    Err, I = 1e-9, 50\n",
    "    kk_lo = 0.0 \n",
    "    kk_hi = gridk_interp[0][1]\n",
    "    foc, i = Err + 1, 0\n",
    "    \n",
    "    # Check if individual is borrowing constrained (if focL<focR at k = kk_lo)\n",
    "    kk = kk_lo\n",
    "    c, n = solve_n(w, p, inv, -(m + kk), σ, ψ, ε, minc)\n",
    "    focR = du_dc(c, σ)\n",
    "    cc = eval_linear(gridk_interp, gridcc, np.array([kk]))\n",
    "    focL = β * R * du_dc(cc, σ)\n",
    "    foc = focL - focR\n",
    "    if foc < Err:\n",
    "        foc = 0\n",
    "    \n",
    "    # Iterate over guesses of kk until foc is satisfied\n",
    "    while np.abs(foc)>Err and i<I:\n",
    "        kk = (kk_lo + kk_hi) / 2\n",
    "        \n",
    "        # Compute marginal cost of saving\n",
    "        c, n = solve_n(w, p, inv, -(m + kk), σ, ψ, ε, minc)\n",
    "        focR = du_dc(c, σ)\n",
    "\n",
    "        # Compute marginal benefit of saving\n",
    "        cc = eval_linear(gridk_interp, gridcc, np.array([kk]))\n",
    "        focL = β * R * du_dc(cc, σ)\n",
    "        \n",
    "        # Evaluate foc and update bounds on savings policy\n",
    "        foc = focL - focR             \n",
    "        kk_lo = kk_lo * (foc<-Err) + kk * (foc>=-Err)\n",
    "        kk_hi = kk * (foc<=Err) + kk_hi * (foc>Err) \n",
    "        i += 1\n",
    "    \n",
    "    if np.abs(foc)>10*Err:\n",
    "        'solve_kk: ERROR! FOC violated. kk=', np.round(kk, 3), ', c=', np.round(c, 3), ', foc=', np.round(foc, 5)\n",
    "    \n",
    "    return c, n, kk\n",
    "\n",
    "# Cell with jit-ted functions that cannot be called from within a class.\n",
    "@jit\n",
    "def solve_policy_p_1(τi, τm, T, Tm, P, W, H, n, h, a, θm, ρ, ϕ, ζ, α, σ, ψ, ε, β, R, gridvv, gridVV, gridCC, gridi, gridK_interp, gridh_interp, minc):\n",
    "    \n",
    "    # Set up value grid corresponding to gridi\n",
    "    gridV, gridN, gridKK = np.zeros_like(gridi), np.zeros_like(gridi), np.zeros_like(gridi)\n",
    "        \n",
    "    # Loop over investment grid \n",
    "    for ni, i in enumerate(gridi):\n",
    "        \n",
    "        # Compute child's expected cont'n value\n",
    "        m = max(Tm, m_given_i(τi, τm, i, W * H, n, θm, ρ))\n",
    "        hh = hc(h, i * n, m, a, H, θm, ρ, ϕ, ζ)\n",
    "        vv = eval_linear(gridh_interp, gridvv, np.array([hh]))\n",
    "        \n",
    "        # Compute parent's utilities\n",
    "        C, N, KK = solve_kk(W * H * n, P, i, m - T - Tm - τm * m - τi * n * i, gridK_interp, gridCC, R, β, σ, ψ, ε, minc)\n",
    "        VV = eval_linear(gridK_interp, gridVV, np.array([KK]))\n",
    "        U = util(C, P - (N + i), σ, ψ, ε)\n",
    "        \n",
    "        # Store outcomes\n",
    "        gridV[ni] = U + β * VV + α * vv\n",
    "        gridN[ni] = N\n",
    "        gridKK[ni] = KK\n",
    "        \n",
    "    # Choose optimal investment level\n",
    "    ni = np.argmax(gridV)\n",
    "    i = gridi[ni]\n",
    "    m = max(Tm, m_given_i(τi, τm, i, W * H, n, θm, ρ))\n",
    "    hh = hc(h, i * n, m, a, H, θm, ρ, ϕ, ζ) \n",
    "    KK = gridKK[ni]\n",
    "    N = gridN[ni]\n",
    "    C = W * H * n * N - m + T + Tm + τi * n * i + τm * m - KK\n",
    "    \n",
    "    return [C, N, KK, i, m, hh]\n",
    "\n",
    "class BlandinHerrington:\n",
    "    \"\"\"\n",
    "    This class computes the outcome of the model in Blandin, Herrington.\n",
    "    College graduates earn a college premium.\n",
    "    Children choose whether to attend college, which is risky and costly.\n",
    "    Probability of graduation conditional on attendance depends on the child's human capital.\n",
    "    Parents choose how much to invest in their child's human capital.\n",
    "\n",
    "    INPUTS:\n",
    "    gridwgt:   population weight grid\n",
    "    minh:      for human capital grid\n",
    "    maxh:      for human capital grid\n",
    "    π_1, π2:   parameters governing the graduation probability technology\n",
    "    τ_m_ps:    market cost of college\n",
    "    τ_n:       time (opportunity) cost of college\n",
    "    w_ng:      wage rate of non-college-graduates\n",
    "    ω_g:       wage premium of college graduates\n",
    "    nbar:      endowment of labor each period\n",
    "    per_length:length of model period\n",
    "    R_yr:      annual interest rate\n",
    "    β_yr:      annual  intertemporal discount rate\n",
    "    σ:         CRRA parameter\n",
    "    loc_ξ:     location parameter for college preference shock\n",
    "    scale_ξ:   scale parameter for college preference shock\n",
    "    σ_H:       sd of adult human capital H\n",
    "    NH:        number of gridpoints for adult human capital H\n",
    "    NsdH:      number of σ_H for gridH to span\n",
    "    \n",
    "    FUNCTIONS:\n",
    "    solve_p_2(self):               returns life-cycle savings, consumption, and value functions for empty-nester parents\n",
    "    solve_c_2(self):               returns life-cycle attendance, completion, earnings, savings, consumption, and value functions for adult children\n",
    "    solve_p_1(self):               returns investment, savings, consumption decisions for parents with children\n",
    "    output_results(self):          outputs key statistics of model solutions\n",
    "    output_results_params(self):   outputs parameter values used\n",
    "    output_figs(self):             outputs figures from model solutions\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,\n",
    "                 λsp,\n",
    "                 h0=200,\n",
    "                 minh=200,\n",
    "                 maxh=800,\n",
    "                 Nh=301, \n",
    "                 θm=0.333,\n",
    "                 ρ=0.6, \n",
    "                 ϕ=0.50,\n",
    "                 ζ=0.275, \n",
    "                 μ_a_ps=np.array([150, 150, 150, 150]).reshape(2,2),\n",
    "                 σ_a=0.1,\n",
    "                 Na=21,\n",
    "                 π1=-4.589,\n",
    "                 π2=0.010,\n",
    "                 τ_m_ps=4*np.array([4_558, 8_140, 6_916, 10_498]).reshape(2,2),\n",
    "                 τ_n=0.27, \n",
    "                 w_ng=0.033,\n",
    "                 ω_g=0.3,\n",
    "                 nbar=5_200,\n",
    "                 per_length=18,\n",
    "                 R_yr=1.04,\n",
    "                 β_yr=1/1.04,\n",
    "                 σ=2.00001,\n",
    "                 ψ=1.0,\n",
    "                 ε=1.01,\n",
    "                 α=0.2,\n",
    "                 scale_ξ=1,\n",
    "                 loc_ξ_0=2,\n",
    "                 μ_H=np.log(500), \n",
    "                 σ_H=1e-5,\n",
    "                 Nk=201,\n",
    "                 NH=1,\n",
    "                 NsdH=1,\n",
    "                 maxi=0.25,\n",
    "                 δi=0.01/3,\n",
    "                 π1ps=-5.543,\n",
    "                 π2ps=0.012,       \n",
    "                 Tm_yr=0.0,\n",
    "                 τi=0.0,\n",
    "                 τm=0.0,\n",
    "                 path='./results/temp/'):\n",
    "        \n",
    "        # Store parameter values that are inputs to the class \n",
    "        self.λsp = λsp\n",
    "        self.h0, self.minh, self.maxh, self.Nh = h0, minh, maxh, Nh\n",
    "        self.θm, self.ρ, self.ϕ, self.ζ = θm, ρ, ϕ, ζ\n",
    "        self.μ_a_ps, self.σ_a, self.Na = μ_a_ps, σ_a, Na\n",
    "        self.π1, self.π2, self.τ_m_ps, self.τ_n = π1, π2, τ_m_ps, τ_n\n",
    "        self.w_ng, self.ω_g, self.nbar, self.per_length, self.R_yr = w_ng, ω_g, nbar, per_length, R_yr\n",
    "        self.β_yr, self.σ, self.ψ, self.ε, self.α = β_yr, σ-1, ψ, ε, α\n",
    "        self.scale_ξ, self.loc_ξ_0, self.μ_H, self.σ_H = scale_ξ, loc_ξ_0, μ_H, σ_H\n",
    "        self.NP, self.NS, self.Nk, self.NH, self.NsdH = 2, 2, Nk, NH, NsdH\n",
    "        self.maxi, self.δi = maxi, δi\n",
    "        self.Tm_yr = Tm_yr\n",
    "        self.path = path\n",
    "        \n",
    "        # Store other model parameter values\n",
    "        self.Nsda = 3\n",
    "        self.R, self.β = self.R_yr**self.per_length, self.β_yr**self.per_length\n",
    "        self.Jc, self.Jp = np.round((70 - 18) / self.per_length), np.round((70 - 36) / self.per_length)\n",
    "        self.w_g = self.w_ng * (1 + self.ω_g)\n",
    "        #self.n = self.nbar * per_length\n",
    "        self.pv_prd = ((1 - self.R_yr**(-self.per_length)) / (1 - self.R_yr**(-1)))\n",
    "        self.n = self.nbar * self.pv_prd\n",
    "        self.loc_ξ = self.loc_ξ_0 - self.scale_ξ * 0.557\n",
    "        self.Ni = 1 + int(self.maxi / self.δi)\n",
    "        self.π1ps, self.π2ps = π1ps, π2ps\n",
    "        self.π1_ps = self.π1ps * np.ones(4).reshape(2,2)\n",
    "        self.π2_ps = self.π2ps * np.ones(4).reshape(2,2)\n",
    "        self.Tm = self.Tm_yr * self.pv_prd\n",
    "        self.τm, self.τi = τm, τi\n",
    "        self.Tτ = 0.0\n",
    "        self.T_yr = 0.0\n",
    "        self.T = self.T_yr * self.pv_prd\n",
    "        \n",
    "        \n",
    "        # Store other computational parameters\n",
    "        self.minc = 1e-6\n",
    "        \n",
    "        # Store basic 1d grids        \n",
    "        self.gridh = np.linspace(self.minh, self.maxh, self.Nh)\n",
    "        \n",
    "        self.gridlH, self.λH = self.Tauchen_1d(self.μ_H, self.σ_H, self.NH, self.NsdH)\n",
    "        self.gridH = np.exp(self.gridlH)\n",
    "        \n",
    "        self.mink, self.maxk = -0.3 * self.w_g * self.maxh * self.n, 0.3 * self.w_g * self.maxh * self.n\n",
    "        self.gridk = np.linspace(self.mink, self.maxk, self.Nk)\n",
    "        \n",
    "        self.gridi = np.linspace(0, self.maxi, self.Ni)\n",
    "        \n",
    "        self.gridsla = np.zeros([self.NP, self.NS, self.Na])\n",
    "        self.λa = np.zeros([self.NP, self.NS, self.Na])\n",
    "        for nP in range(self.NP):\n",
    "            for S in range(self.NS):\n",
    "                μ_a = self.μ_a_ps[nP, S]\n",
    "                self.gridsla[nP, S, :], self.λa[nP, S, :] = self.Tauchen_1d(np.log(μ_a), self.σ_a, self.Na, self.Nsda)\n",
    "        self.gridsa = np.exp(self.gridsla)\n",
    "        \n",
    "        # Store 4d grid of population weights\n",
    "        self.λ = np.zeros([self.NP, self.NS, self.NH, self.Na])\n",
    "        self.λ = gen_popwgts(self.λ, self.λsp, self.λH, self.λa, self.NP, self.NS, self.NH, self.Na)\n",
    "        \n",
    "        # Store 3d grid of parent state variables\n",
    "        self.Shape = (self.NP, self.NS, self.NH, self.Nk)\n",
    "        self.K, self.H, self.P, self.W = np.zeros(self.Shape), np.zeros(self.Shape), np.zeros(self.Shape), np.zeros(self.Shape)\n",
    "        for nP in range(self.NP):\n",
    "            self.P[nP, :, :, :] = 1 + nP\n",
    "        self.W[:, 0, :, :] = self.w_ng\n",
    "        self.W[:, 1, :, :] = self.w_g  \n",
    "        for nH in range(self.NH):\n",
    "            self.H[:, :, nH, :] = self.gridH[nH]        \n",
    "        for nk in range(self.Nk):\n",
    "            self.K[:, :, :, nk] = self.gridk[nk]\n",
    "            \n",
    "        # Generate grids for interpolation during model solution\n",
    "        self.gridK_interp = UCGrid((self.mink, self.maxk, self.Nk))\n",
    "        self.gridh_interp = UCGrid((self.minh, self.maxh, self.Nh))\n",
    "\n",
    "    def Tauchen_1d(self, μ, σ, S, Nsd):\n",
    "        \"\"\"\n",
    "        This function uses a modified Tauchen (1986) method\n",
    "        to approximate a Normal distribution.\n",
    "        \n",
    "        Distribution: s ~ N(μ, σ**2).\n",
    "        \n",
    "        INPUTS:  -μ: mean\n",
    "                 -σ: SD\n",
    "                 -S: number of gridpoints\n",
    "                 -Nsd: number of SD from mean for grid to span\n",
    "        \n",
    "        OUTPUTS: -λ, weights on each gridpoint\n",
    "        \"\"\"\n",
    "        \n",
    "        # Compute grid over state s and the half-distance between gridpoints, δ\n",
    "        grid = np.linspace(μ - Nsd * σ, μ + Nsd * σ, S)\n",
    "        δ = (grid[-1] - grid[0]) / (S - 1) / 2\n",
    "        \n",
    "        # compute cumulative probabilities of grids\n",
    "        λcum = np.ones(S) \n",
    "        for s in range(S-1):\n",
    "            λcum[s] = norm.cdf(grid[s] + δ, loc = μ, scale = σ)\n",
    "        \n",
    "        # compute probabilities of grids\n",
    "        λ = λcum\n",
    "        λ[1:] = λcum[1:] - λcum[:-1]\n",
    "\n",
    "        # Check λ\n",
    "        if np.abs(np.sum(λ) - 1)>1e-9:\n",
    "            print('BlandinHerrington.Tauchen_1d: Distribution grid does not sum to one!')            \n",
    "            \n",
    "        return [grid, λ]\n",
    "        \n",
    "    def solve_p_2(self):\n",
    "        # Unpack parameters for clarity\n",
    "        W, H, K, R, P, n, Jp, σ, ψ, ε, β = self.W, self.H, self.K, self.R, self.P, self.n, self.Jp, self.σ, self.ψ, self.ε, self.β\n",
    "        NP, NS, NH, Nk = self.NP, self.NS, self.NH, self.Nk\n",
    "        \n",
    "        # Solve lifetime consumption, labor, income given state (P, S, K)\n",
    "        Cp, Np = np.zeros([NP, NS, NH, Nk]), np.zeros([NP, NS, NH, Nk])\n",
    "        for nP in range(NP):\n",
    "            for S in range (NS):\n",
    "                for nH in range(NH):\n",
    "                    Cp[nP, S, nH, :], Np[nP, S, nH, :] = solve_c_n(W[nP, S, nH, :] * H[nP, S, nH, :] * P[nP, S, nH, :] * n, R * K[nP, S, nH, :], R, Jp, ψ, ε, σ)\n",
    "        Np = P * Np\n",
    "        Yp = W * H * P * n * Np\n",
    "\n",
    "        # Compute value functions given lifetime incomes\n",
    "        Vp = v_life(P - Np, W * H * P * n * Np, R * K, Jp, σ, ψ, ε, β, R)\n",
    "             \n",
    "        return Vp, Yp, Cp, Np\n",
    "\n",
    "\n",
    "    def solve_c_2(self, h, T): \n",
    "        # Unpack variables for simpler notation\n",
    "        w_ng, w_g, τ_m_ps, τ_n, π1_ps, π2_ps, loc_ξ, scale_ξ, σ, ψ, ε, β, R, Jc, nbar, n = self.w_ng, self.w_g, self.τ_m_ps, self.τ_n, self.π1_ps, self.π2_ps, self.loc_ξ, self.scale_ξ, self.σ, self.ψ, self.ε, self.β, self.R, self.Jc, self.nbar, self.n\n",
    "        NP, NS, Nh = self.NP, self.NS, self.Nh\n",
    "        \n",
    "        # Copute lifetime labor and income given na, a_dropout, a_graduate\n",
    "        coh_na = T\n",
    "        c_na, n_na = solve_c_n(w_ng * h * n, coh_na, R, Jc, ψ, ε, σ)\n",
    "        coh_a, c_a_ng, c_a_g, n_a_ng, n_a_g = np.zeros([NP, NS, Nh]), np.zeros([NP, NS, Nh]), np.zeros([NP, NS, Nh]), np.zeros([NP, NS, Nh]), np.zeros([NP, NS, Nh])\n",
    "        for nP in range(NP):\n",
    "            for S in range (NS):\n",
    "                coh_a[nP, S, :] = T - τ_m_ps[nP, S] - w_ng * h * τ_n * nbar * 4\n",
    "                c_a_ng[nP, S, :], n_a_ng[nP, S, :] = solve_c_n(w_ng * h * n, coh_a[nP, S, :], R, Jc, ψ, ε, σ)\n",
    "                c_a_g[nP, S, :], n_a_g[nP, S, :] = solve_c_n(w_g * h * n, coh_a[nP, S, :], R, Jc, ψ, ε, σ)\n",
    "        \n",
    "        y_na = y_life(w_ng * h * n * n_na, coh_na, R, Jc)\n",
    "        y_a_ng = y_life(w_ng * h * n * n_a_ng, coh_a, R, Jc)\n",
    "        y_a_g = y_life(w_g * h * n * n_a_g, coh_a, R, Jc)\n",
    "\n",
    "        # Compute value functions given lifetime choices\n",
    "        v_a, v_na = np.zeros([NP, NS, Nh]), np.zeros([NP, NS, Nh])\n",
    "        v_na_temp = v_life(1.0 - n_na, w_ng * h * n * n_na, coh_na, Jc, σ, ψ, ε, β, R)\n",
    "        for nP in range(NP):\n",
    "            for S in range (NS):\n",
    "                π1, π2 = π1_ps[nP, S], π2_ps[nP, S]\n",
    "                v_a[nP, S, :] = vc_life(w_g * n, w_ng * n, n_a_g[nP, S, :], n_a_ng[nP, S, :], coh_a[nP, S, :], h, π1, π2, σ, ψ, ε, β, R, Jc)\n",
    "                v_na[nP, S, :] = v_na_temp\n",
    "        \n",
    "        # Compute expected model outcomes (taking expectation over ξ)\n",
    "        prob_a_ps = gumbel_l.cdf(v_a - v_na, loc=loc_ξ, scale=scale_ξ)\n",
    "        \n",
    "        # Compute expected value function given hc\n",
    "        v = prob_a_ps * v_a + (1 - prob_a_ps) * v_na\n",
    "\n",
    "        return prob_a_ps, v, v_na, v_a, y_na, y_a_ng, y_a_g, c_na, c_a_ng, c_a_g, n_na, n_a_ng, n_a_g\n",
    "    \n",
    "\n",
    "    def solve_p_1(self, prob_a_ps, vv, VV, CC, n_na, n_a_ng, n_a_g):\n",
    "        # Unpack parameters for clarity\n",
    "        NP, NS, NH, Na = self.NP, self.NS, self.NH, self.Na\n",
    "        h0, gridsa, θm, ρ, ϕ, ζ, π1_ps, π2_ps = self.h0, self.gridsa, self.θm, self.ρ, self.ϕ, self.ζ, self.π1_ps, self.π2_ps\n",
    "        n, w_ng, w_g = self.n, self.w_ng, self.w_g\n",
    "        α, σ, ψ, ε, β, R, minc = self.α, self.σ, self.ψ, self.ε, self.β, self.R, self.minc\n",
    "        gridK_interp, gridh_interp, gridH, gridi = self.gridK_interp, self.gridh_interp, self.gridH, self.gridi\n",
    "        τi, τm, Tm, T = self.τi, self.τm, self.Tm, self.T\n",
    "        \n",
    "        # Initialize policy shells\n",
    "        mC, mN, mKK, mi, mm, mhh = np.zeros([NP, NS, NH, Na]), np.zeros([NP, NS, NH, Na]), np.zeros([NP, NS, NH, Na]), np.zeros([NP, NS, NH, Na]), np.zeros([NP, NS, NH, Na]), np.zeros([NP, NS, NH, Na])\n",
    "        \n",
    "        # Loop over parent state space\n",
    "        for nP in range(NP):\n",
    "            P = nP + 1\n",
    "            for S in range(NS):\n",
    "                W = w_ng * (S==0) + w_g * (S==1)\n",
    "                grida = gridsa[nP, S, :]\n",
    "                for nH in range(NH):\n",
    "                    H = gridH[nH]\n",
    "                    \n",
    "                    for na in range(Na):\n",
    "                        a = grida[na]\n",
    "                        # Solve for optimal policy\n",
    "                        [C, N, KK, i, m, hh] = solve_policy_p_1(τi, τm, T, Tm, P, W, H, n, h0, a, θm, ρ, ϕ, ζ, α, σ, ψ, ε, β, R, vv[nP, S, :], VV[nP, S, nH, :], CC[nP, S, nH, :], gridi, gridK_interp, gridh_interp, minc)\n",
    "                        \n",
    "                        # Adjust nominal figures into annual values\n",
    "                        C, KK, m = C / self.pv_prd, KK / self.pv_prd, m / self.pv_prd\n",
    "                        # Store results\n",
    "                        mC[nP, S, nH, na], mN[nP, S, nH, na], mKK[nP, S, nH, na], mi[nP, S, nH, na], mm[nP, S, nH, na], mhh[nP, S, nH, na] = [C, N, KK, i, m, hh]\n",
    "\n",
    "        # Compute attendance probabilities\n",
    "        mattend = np.zeros([NP, NS, NH, Na])\n",
    "        for nP in range(NP):\n",
    "            for S in range(NS):\n",
    "                prob_a = prob_a_ps[nP, S, :]        \n",
    "                pts_hh = np.array([mhh[nP, S, :, :].reshape(NH * Na)]).T\n",
    "                mattend_temp = 1e-5 + eval_linear(gridh_interp, prob_a, pts_hh)\n",
    "                mattend_temp = mattend_temp.reshape(NH, Na)\n",
    "                mattend[nP, S, :, :] = mattend_temp.reshape(NH, Na)\n",
    "        \n",
    "        # Compute graduation probabilities (unconditional on attendance)\n",
    "        mgrad = np.zeros([NP, NS, NH, Na])\n",
    "        for nP in range(NP):\n",
    "            for S in range(NS):\n",
    "                π1, π2 = π1_ps[nP, S], π2_ps[nP, S]\n",
    "                mgrad[nP, S, :, :] = γ(mhh[nP, S, :, :], π1, π2) * mattend[nP, S, :, :]\n",
    "                \n",
    "        \n",
    "        # Compute mean hours (unconditional on attendance)\n",
    "        # and hours given non-attendance, hours given attend/non-graduate, attend/graduate\n",
    "        mn, mn_na, mn_ng, mn_g = np.zeros([NP, NS, NH, Na]), np.zeros([NP, NS, NH, Na]), np.zeros([NP, NS, NH, Na]), np.zeros([NP, NS, NH, Na])\n",
    "        for nP in range(NP):\n",
    "            for S in range(NS):\n",
    "                pts_hh = np.array([mhh[nP, S, :, :].reshape(NH * Na)]).T\n",
    "                nna, na_ng, na_g = eval_linear(gridh_interp, n_na, pts_hh), eval_linear(gridh_interp, n_a_ng[nP, S, :], pts_hh), eval_linear(gridh_interp, n_a_g[nP, S, :], pts_hh)\n",
    "                nna, na_ng, na_g = nna.reshape(NH, Na), na_ng.reshape(NH, Na), na_g.reshape(NH, Na)\n",
    "                mn_na[nP, S, :, :], mn_ng[nP, S, :, :], mn_g[nP, S, :, :] = nna, na_ng, na_g\n",
    "                pna, pa_ng, pa_g = 1 - mattend[nP, S, :, :], mattend[nP, S, :, :] - mgrad[nP, S, :, :], mgrad[nP, S, :, :]\n",
    "                mn[nP, S, :, :] = pna * nna + pa_ng * na_ng + pa_g * na_g \n",
    "\n",
    "        return [mC, mN, mKK, mi, mm, mhh, mattend, mgrad, mn, mn_na, mn_ng, mn_g]\n",
    "\n",
    "\n",
    "    def gen_stats_earn(self, mN, mi, mhh, mattend, mgrad, y2_na, y2_a_ng, y2_a_g):\n",
    "        # Unpack parameters\n",
    "        NP, NS, NH, Na = self.NP, self.NS, self.NH, self.Na\n",
    "        π1_ps, π2_ps, w_ng, w_g, n, gridH = self.π1_ps, self.π2_ps, self.w_ng, self.w_g, self.n, self.gridH\n",
    "        \n",
    "        # Set up variable shells\n",
    "        mE  = np.zeros([NP, NS, NH, Na])\n",
    "        meph_na, meph_ang, meph_g, meph, me, me_net = np.zeros_like(mE), np.zeros_like(mE), np.zeros_like(mE), np.zeros_like(mE), np.zeros_like(mE), np.zeros_like(mE)\n",
    "\n",
    "        # Loop over parent state space\n",
    "        for nP in range(NP):\n",
    "            P = nP + 1\n",
    "            for S in range(NS):\n",
    "                W = w_ng * (S==0) + w_g * (S==1)\n",
    "                π1, π2 = π1_ps[nP, S], π2_ps[nP, S]\n",
    "                for nH in range(NH):\n",
    "                    H = n * gridH[nH]\n",
    "                    for na in range(Na):\n",
    "                        # Parent earnings\n",
    "                        mE[nP, S, nH, na] = W * H * mN[nP, S, nH, na] # * P\n",
    "                        \n",
    "                        # Child earnings\n",
    "                        hh = mhh[nP, S, nH, na]\n",
    "                        proba, probg_a = mattend[nP, S, nH, na], γ(hh, π1, π2)\n",
    "                        pts_hh = np.array([hh])\n",
    "                        y_na = eval_linear(self.gridh_interp, y2_na, pts_hh)\n",
    "                        y_ng = eval_linear(self.gridh_interp, y2_a_ng[nP, S, :], pts_hh)\n",
    "                        y_g = eval_linear(self.gridh_interp, y2_a_g[nP, S, :], pts_hh)\n",
    "                        meph_na[nP, S, nH, na] = w_ng * hh\n",
    "                        meph_ang[nP, S, nH, na] = w_ng * hh\n",
    "                        meph_g[nP, S, nH, na] = w_g * hh\n",
    "                        meph[nP, S, nH, na] = (1 - proba) * meph_na[nP, S, nH, na] + (proba - probg_a) * meph_ang[nP, S, nH, na] + probg_a * meph_g[nP, S, nH, na]\n",
    "\n",
    "                        # child earnings, gross and net of tuition\n",
    "                        me[nP, S, nH, na] = (1 - proba) * y_na + (proba - probg_a) * (y_ng + self.τ_m_ps[nP, S]) + probg_a * (y_g + self.τ_m_ps[nP, S])\n",
    "                        me_net[nP, S, nH, na] = (1 - proba) * y_na + (proba - probg_a) * y_ng + probg_a * y_g\n",
    "\n",
    "        return mE, meph_na, meph_ang, meph_g, meph, me, me_net\n",
    "    \n",
    "    \n",
    "    def reg_gradprob(self, mE, mgrad):\n",
    "        \"\"\"\n",
    "        regress college grad probability on log parent earnings and family type\n",
    "        \"\"\"\n",
    "        # infer population sizes\n",
    "        NP, NS, NH, Na = np.shape(mE)\n",
    "        N, Nf = np.prod(np.shape(mE)), NP * NS\n",
    "\n",
    "        # construct matrix of family types \n",
    "        mftype = np.zeros_like(mE)\n",
    "        for nP in range(NP):\n",
    "            for nS in range(NS):\n",
    "                mftype[nP, nS, :, :] = nP * NS + nS\n",
    "        mftype = mftype.astype(int)\n",
    "\n",
    "        # construct regression variables (dummies for family type)\n",
    "        y, x, λ= mgrad.reshape(N), np.log(mE.reshape(N)), self.λ.reshape(N)\n",
    "        for f in np.arange(Nf):\n",
    "            x = np.vstack((x, np.where(mftype==f, 1, 0).reshape(N)))            \n",
    "        x = x.T\n",
    "\n",
    "        # run regression\n",
    "        model = sm.WLS(y, x, weights=λ)\n",
    "        results = model.fit()\n",
    "        return results    \n",
    "        \n",
    "\n",
    "    def gen_stats(self, mN, mi, mm, mhh, mattend, mgrad, mn, y2_na, y2_a_ng, y2_a_g):\n",
    "        \n",
    "        ### Compute earnings-related stats\n",
    "        mE, meph_na, meph_ang, meph_g, meph, me, me_net = self.gen_stats_earn(mN, mi, mhh, mattend, mgrad, y2_na, y2_a_ng, y2_a_g)\n",
    "\n",
    "        ### Compute means by SP and aggregate means\n",
    "        # Unconditional means\n",
    "        d_ps, d_ps_sd, d_agg, d_agg_sd = {}, {}, {}, {}\n",
    "        variables = [np.log(mE), mN, mi, mm, mhh, mattend, mgrad, meph, mn, me, me_net, np.log(me), np.log(me_net)]\n",
    "        labels = ['lE', 'N', 'i', 'm', 'hh', 'sh_a', 'sh_g', 'eph', 'n', 'e', 'e_net', 'le', 'le_net']\n",
    "        for lbl, v in zip(labels, variables):\n",
    "            if lbl=='i':\n",
    "                v[1, :, :, :] = v[1, :, :, :] / 2\n",
    "            d_ps[lbl] = np.average(v, axis=(2, 3), weights=self.λ)\n",
    "            d_agg[lbl] = np.average(v, weights=self.λ)\n",
    "            d_agg_sd[\"{}\".format(lbl)], d_ps_sd[\"{}\".format(lbl)] = sd_weighted(v, self.λsp, self.λ)\n",
    "        \n",
    "        # Conditional means\n",
    "        variables = [mhh, mhh, mhh, np.log(meph_na), np.log(meph_ang), np.log(meph_g), np.log(me), np.log(me_net)]\n",
    "        labels = ['hh_na', 'hh_a', 'hh_g', 'leph_na', 'leph_a', 'leph_g', 'le', 'le_net']\n",
    "        probs = [1 - mattend, mattend, mgrad, 1 - mattend, mattend, mgrad]\n",
    "        for lbl, v, p in zip(labels, variables, probs):\n",
    "            d_ps[\"{}\".format(lbl)] = np.average(v, axis=(2, 3), weights=self.λ * p)\n",
    "            d_agg[\"{}\".format(lbl)] = np.average(v, weights=self.λ * p)\n",
    "            d_agg_sd[\"{}\".format(lbl)], d_ps_sd[\"{}\".format(lbl)] = sd_weighted(v, self.λsp, self.λ * p)\n",
    "        \n",
    "        # regress college grad probability on log parent earnings and family type\n",
    "        reg_gradprob_results = self.reg_gradprob(mE, mgrad)\n",
    "        \n",
    "        return d_ps, d_agg, d_agg_sd, reg_gradprob_results\n",
    "\n",
    "    \n",
    "    def maketab5(self, reg):\n",
    "        # output results of college completion regression\n",
    "        est = reg.params\n",
    "        est[1:] = est[1:] - est[3]\n",
    "        est = np.hstack((est[:3], est[4]))\n",
    "        fpath = '../output/tables/table5.csv'\n",
    "        with open(fpath, 'w', newline='') as f:\n",
    "            pen = csv.writer(f)\n",
    "            pen.writerow([' ', 'Data coefficient', 'Model coefficient', 'Model / Data'])\n",
    "            pen.writerow(['1L', -0.076, np.round(est[1], 3), np.round(est[1] / -0.076, 2)])\n",
    "            pen.writerow([' ', 0.018])\n",
    "            pen.writerow(['1H', 0.107,  np.round(est[2], 3), np.round(est[2] / 0.107, 2)])\n",
    "            pen.writerow([' ', 0.035])\n",
    "            pen.writerow(['2H', 0.318,  np.round(est[3], 3), np.round(est[3] / 0.318, 2)])\n",
    "            pen.writerow([' ', 0.020])\n",
    "            pen.writerow(['Parent earnings', 0.092,  np.round(est[0], 3), np.round(est[0] / 0.092, 2)])\n",
    "            pen.writerow([' ', 0.010])\n",
    "    \n",
    "    \n",
    "    def output_results(self, d_ps, d_agg, d_agg_sd, prob_a_ps, reg, path_data, output=False):\n",
    "        #self.output_results_params()\n",
    "        self.output_results_stats(d_ps, d_agg, d_agg_sd, reg)\n",
    "        self.output_results_statsvsdata(d_ps, d_agg, path_data)\n",
    "\n",
    "    def output_results_params(self):\n",
    "        #List of parameter titles\n",
    "        titles = ['taui', 'taum', 'T_yr', 'T', 'Tm_yr', 'Tm', 'Ttuit', 'minh', 'maxh', 'Nh', 'NH', 'mu_H', 'sigma_H', 'mu_a_ps', 'sigma_a', 'Na', 'psi', 'elast', 'alpha', 'theta_m', 'phi', 'rho', 'pi1_ps', 'pi2_ps', 'tau_m_ps', 'tau_n', 'omega_g', 'w_ng', 'w_g', 'nbar', 'R', 'Jc', 'Jp', 'beta', 'sigma', 'scale_xi', 'loc_xi_0', 'zeta']\n",
    "        values = [self.τi, self.τm, self.T_yr, self.T, self.Tm_yr, self.Tm, self.Tτ, self.minh, self.maxh, self.Nh, self.NH, self.μ_H, self.σ_H, self.μ_a_ps, self.σ_a, self.Na, self.ψ, self.ε, self.α, self.θm, self.ϕ, self.ρ, self.π1, self.π2, self.τ_m_ps, self.τ_n, self.ω_g, self.w_ng, self.w_g, self.nbar, self.R, self.Jc, self.Jp, self.β, self.σ, self.scale_ξ, self.loc_ξ_0, self.ζ]\n",
    "\n",
    "        # Initialize csv I will write parameters to\n",
    "        fpath = self.path + 'params.csv'\n",
    "        with open(fpath, 'w', newline='') as f:\n",
    "            pen = csv.writer(f)\n",
    "            pen.writerow(titles)\n",
    "            pen.writerow(values)\n",
    "\n",
    "\n",
    "    def output_results_stats(self, d_ps, d_agg, d_agg_sd, reg):\n",
    "        fullpath = self.path + 'stats.csv'\n",
    "        est, se = list(reg.params), list(reg.bse)\n",
    "        est[1:] = est[1:] - est[3]\n",
    "        with open(fullpath, 'w', newline='') as f:\n",
    "            pen = csv.writer(f)\n",
    "            pen.writerow(['variable', 'Agg, Mn', 'Agg, SD', '1L', '1H', '2L', '2H']) \n",
    "            weights = ['w_ps', np.sum(self.λsp), '']\n",
    "            weights.extend(self.λsp.reshape(4).tolist())\n",
    "            pen.writerow(weights)\n",
    "            for lbl in d_agg.keys():\n",
    "                if lbl!='i':\n",
    "                    statlist = [lbl, d_agg[lbl], d_agg_sd[lbl]]\n",
    "                    statlist.extend(d_ps[lbl].reshape(4).tolist())\n",
    "                else:\n",
    "                    statlist = [lbl, 100 * d_agg[lbl], 100 * d_agg_sd[lbl]]\n",
    "                    statlist.extend((100 * d_ps[lbl]).reshape(4).tolist())\n",
    "                pen.writerow(statlist)\n",
    "             \n",
    "                \n",
    "    def output_results_statsvsdata(self, d_ps, d_agg, path_data):\n",
    "        # Set path for output\n",
    "        fullpath = self.path + 'statsvsdata.csv'\n",
    "        \n",
    "        # Import data moments\n",
    "        df = pd.read_csv(path_data)\n",
    "        df = df.transpose()\n",
    "        df.columns = df.iloc[0]\n",
    "        labels = list(df)\n",
    "        list(df['i'])\n",
    "        \n",
    "        # Write model and data moments to output\n",
    "        with open(fullpath, 'w', newline='') as f:\n",
    "            pen = csv.writer(f)\n",
    "            pen.writerow(['DATA'])\n",
    "            pen.writerow(['Variable', 'Agg, Mn', '1L', '1H', '2L', '2H']) \n",
    "            for lbl in labels:\n",
    "                pen.writerow(list(df[lbl]))\n",
    "            labels.remove('w_ps')\n",
    "            pen.writerow(['MODEL'])\n",
    "            pen.writerow(['Variable', 'Agg, Mn', '1L', '1H', '2L', '2H']) \n",
    "            weights = ['w_ps', np.sum(self.λsp)]\n",
    "            weights.extend(self.λsp.reshape(4).tolist())\n",
    "            pen.writerow(weights)\n",
    "            for lbl in labels:\n",
    "                statlist = [lbl, d_agg[lbl]]\n",
    "                statlist.extend(d_ps[lbl].reshape(4).tolist())\n",
    "                pen.writerow(statlist)\n",
    "                             \n",
    "                             \n",
    "    def output_results_figs(self, prob_a_ps):\n",
    "        # Unpack parameters\n",
    "        gridh, π1_ps, π2_ps = self.gridh, self.π1_ps, self.π2_ps\n",
    "        \n",
    "        ### Loop over (P, S) states\n",
    "        for nP in range(self.NP):\n",
    "            for S in range(self.NS):\n",
    "                π1, π2 = π1_ps[nP, S], π2_ps[nP, S]\n",
    "                prob_a = prob_a_ps[nP, S, :]\n",
    "                \n",
    "                # Compute necessary profiles\n",
    "                prob_g_a = γ(gridh, π1, π2)\n",
    "                prob_g = prob_g_a * prob_a\n",
    "\n",
    "                # Plot attendance probability as a function of hh\n",
    "                fig, ax = plt.subplots()\n",
    "                ax.plot(gridh, prob_a, linestyle='dotted', label='Attendance')\n",
    "                ax.plot(gridh, prob_g_a, linestyle='dashed', label='Graduation, Conditional')\n",
    "                ax.plot(gridh, prob_g, label='Graduation, Unconditional')\n",
    "                ax.set_xlabel('Child Human Capital (SAT)')\n",
    "                ax.set_ylabel('Share of Population')\n",
    "                ax.legend()\n",
    "                plt.show()\n",
    "                fullpath = self.path + 'attainment_profiles_P{}_S{}.pdf'.format(nP, S)\n",
    "                fig.savefig(fullpath, bbox_inches='tight') \n",
    "\n",
    "def run_parametrized_model(bh, path_data, output=False):\n",
    "    prob_a, v2, v2_na, v2_a, y2_na, y2_a_ng, y2_a_g, c_na, c_a_ng, c_a_g, n_na, n_a_ng, n_a_g = bh.solve_c_2(h=bh.gridh, T=0)\n",
    "    V2, Y2, C2, N2 = bh.solve_p_2()\n",
    "    [mC, mN, mKK, mi, mm, mhh, mattend, mgrad, mn, mn_na, mn_ng, mn_g] = bh.solve_p_1(prob_a, v2, V2, C2, n_na, n_a_ng, n_a_g)\n",
    "    d_ps, d_agg, d_agg_sd, reg_gradprob_results = bh.gen_stats(mN, mi, mm, mhh, mattend, mgrad, mn, y2_na, y2_a_ng, y2_a_g)\n",
    "    if output==True:\n",
    "        bh.output_results(d_ps, d_agg, d_agg_sd, prob_a, reg_gradprob_results, path_data)\n",
    "    return d_ps, d_agg, d_agg_sd, prob_a, mhh, reg_gradprob_results\n",
    "\n",
    "def run_counterfactual(bh_in, path_data, invonly=False, prob_a_fixed=0, τ_m_ps=4*np.array([3_345, 5_657, 2_534, 4_846]).reshape(2,2)):\n",
    "    bh = deepcopy(bh_in)\n",
    "    bh.τ_m_ps = τ_m_ps\n",
    "    prob_a, v2, v2_na, v2_a, y2_na, y2_a_ng, y2_a_g, c_na, c_a_ng, c_a_g, n_na, n_a_ng, n_a_g = bh.solve_c_2(h=bh.gridh, T=0)\n",
    "    if invonly==True:\n",
    "        v2 = prob_a * v2_a + (1 - prob_a) * v2_na\n",
    "        prob_a = prob_a_fixed\n",
    "    V2, Y2, C2, N2 = bh.solve_p_2()\n",
    "    [mC, mN, mKK, mi, mm, mhh, mattend, mgrad, mn, mn_na, mn_ng, mn_g] = bh.solve_p_1(prob_a, v2, V2, C2, n_na, n_a_ng, n_a_g)\n",
    "    d_ps, d_agg, d_agg_sd, reg_gradprob_results = bh.gen_stats(mN, mi, mm, mhh, mattend, mgrad, mn, y2_na, y2_a_ng, y2_a_g)\n",
    "    return d_ps, d_agg, d_agg_sd, prob_a, reg_gradprob_results\n",
    "\n",
    "def decompose_ineq(bh_in, ω_g, λsp, path_ctrf, path_data):\n",
    "    # solve model using input parameters\n",
    "    bh_out = deepcopy(bh_in)\n",
    "    prob_a, v2, v2_na, v2_a, y2_na, y2_a_ng, y2_a_g, c_na, c_a_ng, c_a_g, n_na, n_a_ng, n_a_g = bh_out.solve_c_2(h=bh_out.gridh, T=0)\n",
    "    V2, Y2, C2, N2 = bh_out.solve_p_2()\n",
    "    [mC, mN, mKK, mi, mm, mhh, mattend, mgrad, mn, mn_na, mn_ng, mn_g] = bh_out.solve_p_1(prob_a, v2, V2, C2, n_na, n_a_ng, n_a_g)\n",
    "    \n",
    "    # load in counterfactual parameters\n",
    "    bh_out.ω_g = ω_g\n",
    "    bh_out.w_g = bh_out.w_ng * (1 + bh_out.ω_g)\n",
    "    bh_out.λsp = λsp\n",
    "    bh_out.λa = np.zeros([bh_out.NP, bh_out.NS, bh_out.Na])\n",
    "    for nP in range(bh_out.NP):\n",
    "        for S in range(bh_out.NS):\n",
    "            μ_a = bh_out.μ_a_ps[nP, S]\n",
    "            bh_out.gridsla[nP, S, :], bh_out.λa[nP, S, :] = bh_out.Tauchen_1d(np.log(μ_a), bh_out.σ_a, bh_out.Na, bh_out.Nsda)\n",
    "    bh_out.gridsa = np.exp(bh_out.gridsla)\n",
    "    bh_out.λ = np.zeros([bh_out.NP, bh_out.NS, bh_out.NH, bh_out.Na])\n",
    "    bh_out.λ = gen_popwgts(bh_out.λ, bh_out.λsp, bh_out.λH, bh_out.λa, bh_out.NP, bh_out.NS, bh_out.NH, bh_out.Na)\n",
    "    bh_out.path = path_ctrf\n",
    "    \n",
    "    # compute stats with counterfactual parameters\n",
    "    d_ps, d_agg, d_agg_sd, reg_gradprob_results = bh_out.gen_stats(mN, mi, mm, mhh, mattend, mgrad, mn, y2_na, y2_a_ng, y2_a_g)\n",
    "    bh_out.output_results(d_ps, d_agg, d_agg_sd, prob_a, reg_gradprob_results, path_data)\n",
    "    return bh_out\n",
    "\n",
    "def compare_baseline_ctrf(bh_early, bh_late):\n",
    "    \n",
    "    # Read stats from baseline and counterfactual models\n",
    "    df_1 = pd.read_csv(bh_early.path + 'stats.csv')\n",
    "    df_2 = pd.read_csv(bh_late.path + 'stats.csv')  \n",
    "    \n",
    "    # Compute difference between later and earlier\n",
    "    df_3 = df_1.copy()\n",
    "    df_3.iloc[:, 1:] = df_2.iloc[:, 1:] - df_1.iloc[:, 1:]\n",
    "    \n",
    "    # Write to new csv the difference btween counterfactual and baseline\n",
    "    fpath_3 = bh_early.path + 'stats_change.csv'\n",
    "    df_3.to_csv(fpath_3)\n",
    "    \n",
    "def counterfactual_isubsidy(bh, path_data, T=0.0, minτi=0.0, maxτi=12, Nτi=40):\n",
    "    Err, I = 1, Nτi\n",
    "    diff, i = Err + 1, 0\n",
    "    τi_lo, τi_hi = minτi, maxτi\n",
    "\n",
    "    # Iterate over guesses of τi unτil avg. hh_1L matches avg. hh_2L\n",
    "    while np.abs(diff)>Err and i<I:\n",
    "        τi = (τi_lo + τi_hi) / 2\n",
    "        \n",
    "        # Solve model given τi\n",
    "        bh.τi = τi\n",
    "        d_ps, d_agg, d_agg_sd, prob_a, hh, reg_gradprob_results = run_parametrized_model(bh, path_data)\n",
    "        \n",
    "        # Compare average hh_1L to target hh_2L\n",
    "        T_implied = bh.n * d_ps['i'][0, 0] * τi\n",
    "        diff = T_implied - T*1.25\n",
    "        \n",
    "        # Adjust guess of τi accordingly\n",
    "        τi_lo = np.where(diff>Err, τi_lo, τi)\n",
    "        τi_hi = np.where(diff<-Err, τi_hi, τi)\n",
    "        i += 1\n",
    "    \n",
    "    bh.τi_yr = bh.τi / bh.pv_prd\n",
    "    bh.output_results(d_ps, d_agg, d_agg_sd, prob_a, reg_gradprob_results, path_data)\n",
    "    return \n",
    "\n",
    "def counterfactual_msubsidy(bh, path_data, T=0.0, minτm=0.0, maxτm=1, Nτm=40):\n",
    "    Err, I = 1, Nτm\n",
    "    diff, i = Err + 1, 0\n",
    "    τm_lo, τm_hi = minτm, maxτm\n",
    "\n",
    "    # Iterate over guesses of τm unτml avg. hh_1L matches avg. hh_2L\n",
    "    while np.abs(diff)>Err and i<I:\n",
    "        τm = (τm_lo + τm_hi) / 2\n",
    "        \n",
    "        # Solve model given τm\n",
    "        bh.τm = τm\n",
    "        d_ps, d_agg, d_agg_sd, prob_a, hh, reg_gradprob_results = run_parametrized_model(bh, path_data)\n",
    "        \n",
    "        # Compare average hh_1L to target hh_2L\n",
    "        T_implied = d_ps['m'][0, 0] * τm\n",
    "        diff = T_implied - T*1.25     \n",
    "        \n",
    "        # Adjust guess of τm accordingly\n",
    "        τm_lo = np.where(diff>Err, τm_lo, τm)\n",
    "        τm_hi = np.where(diff<-Err, τm_hi, τm)\n",
    "        i += 1\n",
    "    \n",
    "    bh.τm_yr = bh.τm / bh.pv_prd\n",
    "    bh.output_results(d_ps, d_agg, d_agg_sd, prob_a, reg_gradprob_results, path_data)\n",
    "    return \n",
    "\n",
    "def counterfactual_tuitionsubsidy(bh, path_data, attend_2L=.605, minTτ=0.0, maxTτ=40_000, NTτ=40):\n",
    "    Err, I = 1e-3, NTτ\n",
    "    diff, i = Err + 1, 0\n",
    "    Tτ_lo, Tτ_hi = minTτ, maxTτ\n",
    "    τ_0 = bh.τ_m_ps[0, 0]\n",
    "\n",
    "    # Iterate over guesses of Tτ until avg. attend_1L matches attend_2L\n",
    "    while np.abs(diff)>Err and i<I:\n",
    "        Tτ = (Tτ_lo + Tτ_hi) / 2\n",
    "        \n",
    "        # Solve model given Tτ\n",
    "        bh.Tτ = Tτ\n",
    "        bh.τ_m_ps = (τ_0 - bh.Tτ) * np.ones([2, 2])\n",
    "        d_ps, d_agg, d_agg_sd, prob_a, hh, reg_gradprob_results = run_parametrized_model(bh, path_data)\n",
    "        \n",
    "        # Compare average hh_1L to target hh_2L\n",
    "        attend_1L = d_ps['sh_a'][0, 0]\n",
    "        diff = attend_1L - attend_2L\n",
    "        \n",
    "        # Adjust guess of Tτ accordingly\n",
    "        Tτ_lo = np.where(diff>Err, Tτ_lo, Tτ)\n",
    "        Tτ_hi = np.where(diff<-Err, Tτ_hi, Tτ)\n",
    "        i += 1\n",
    "    \n",
    "    bh.output_results(d_ps, d_agg, d_agg_sd, prob_a, reg_gradprob_results, path_data)\n",
    "    return Tτ\n",
    "\n",
    "def counterfactual_mtransfer(bh, path_data, attend_2L=.605, minTm=0.0, maxTm=100_000, NTm=40):\n",
    "    Err, I = 1e-3, NTm\n",
    "    diff, i = Err + 1, 0\n",
    "    Tm_lo, Tm_hi = minTm, maxTm\n",
    "\n",
    "    # Iterate over guesses of Tm until avg. hh_1L matches avg. hh_2L\n",
    "    while np.abs(diff)>Err and i<I:\n",
    "        Tm = (Tm_lo + Tm_hi) / 2\n",
    "        \n",
    "        # Solve model given Tm\n",
    "        bh.Tm = Tm\n",
    "        d_ps, d_agg, d_agg_sd, prob_a, hh, reg_gradprob_results = run_parametrized_model(bh, path_data)\n",
    "        \n",
    "        # Compare average hh_1L to target hh_2L\n",
    "        attend_1L = d_ps['sh_a'][0, 0]\n",
    "        diff = attend_1L - attend_2L\n",
    "        \n",
    "        # Adjust guess of Tm accordingly\n",
    "        Tm_lo = np.where(diff>Err, Tm_lo, Tm)\n",
    "        Tm_hi = np.where(diff<-Err, Tm_hi, Tm)\n",
    "        i += 1\n",
    "    \n",
    "    bh.Tm_yr = bh.Tm / bh.pv_prd\n",
    "    bh.output_results(d_ps, d_agg, d_agg_sd, prob_a, reg_gradprob_results, path_data)\n",
    "    return \n",
    "\n",
    "def counterfactual_transfer(bh, path_data, T=0.0):\n",
    "\n",
    "    bh.T = T\n",
    "    d_ps, d_agg, d_agg_sd, prob_a, hh, reg_gradprob_results = run_parametrized_model(bh, path_data)\n",
    "    \n",
    "    bh.T_yr = bh.T / bh.pv_prd\n",
    "    bh.output_results(d_ps, d_agg, d_agg_sd, prob_a, reg_gradprob_results, path_data)\n",
    "    return \n",
    "\n",
    "def calibrate(mn_m,\n",
    "              mn_i,\n",
    "              mn_prem,\n",
    "              sd_hh,\n",
    "              share_a,\n",
    "              share_a_ps,\n",
    "              mn_hh,\n",
    "              mn_hh_ps,\n",
    "              λsp, \n",
    "              σ,\n",
    "              ε=2.0, \n",
    "              ψ=1.0,\n",
    "              ρ=0.7,\n",
    "              σ_a=.175,\n",
    "              ζ=0.275,\n",
    "              σ_H=1e-5,\n",
    "              NH=2,\n",
    "              NsdH=1.0, \n",
    "              scale_ξ=1.0,\n",
    "              maketab=False,\n",
    "              path='./results/temp/',\n",
    "              path_data=''):\n",
    "    \n",
    "    ### Initialize parameters for calibration\n",
    "    params = {0: 'theta_m', 1: 'alpha', 2: 'omega_g / omega_ng', 3: 'mu_xi', 4: 'mu_a_g', 5: 'phi', 6: 'mu_a_ng', 7: 'eta', 8: 'psi', 9: 'sigma_a', 10: 'sigma_xi', 11: 'sigma_H'}\n",
    "    moments = {0: 'mean_m', 1: 'mean_i', 2: 'e_g / e_ng', 3: 'share_a', 4: 'mean_hh_2h', 5: 'mean_hh_2l', 6: 'mean_hh_1l', 7: 'coeff_loge', 8: 'mean_n', 9: 'sd_hh', 10: 'corr(hh, attend)', 11: 'var(log E)'}\n",
    "    Err = {0: 1, 1: .001, 2: .005, 3: .002, 4: 1.0, 5: 1.0, 6: 1.0}\n",
    "    I = {0: 7, 1: 5, 2: 10, 3: 10, 4: 15, 5: 1, 6: 15} \n",
    "    bnd = {0: [0.03, 0.06], 1: [0.6, 0.8], 2: [0.30, 0.70], 3: [-2.0, 1.0], 4: [0.0, 200.0], 5: [0.26, 0.26], 6: [0.0, 160.0]}\n",
    "\n",
    "    ### Perform nested calibration\n",
    "    bnd0 = np.copy(bnd[0])\n",
    "    err0, i0 = 1 + Err[0], 0\n",
    "    while np.abs(err0)>Err[0] and i0<I[0]:\n",
    "        θm = (bnd0[0] + bnd0[1]) / 2\n",
    "        \n",
    "        bnd1 = np.copy(bnd[1])\n",
    "        err1, i1 = 1 + Err[1], 0\n",
    "        while np.abs(err1)>Err[1] and i1<I[1]:\n",
    "            α = (bnd1[0] + bnd1[1]) / 2\n",
    "\n",
    "            bnd2 = np.copy(bnd[2])\n",
    "            err2, i2 = 1 + Err[2], 0\n",
    "            while np.abs(err2)>Err[2] and i2<I[2]:\n",
    "                ω_g = (bnd2[0] + bnd2[1]) / 2\n",
    "\n",
    "                bnd3 = np.copy(bnd[3])\n",
    "                err3, i3 = 1 + Err[3], 0\n",
    "                while np.abs(err3)>Err[3] and i3<I[3]:\n",
    "                    loc_ξ_0 = (bnd3[0] + bnd3[1]) / 2\n",
    "\n",
    "                    bnd4 = np.copy(bnd[4])\n",
    "                    err4, i4 = 1 + Err[4], 0\n",
    "                    \n",
    "                    μ_a_g = (bnd4[0] + bnd4[1]) / 2\n",
    "                    \n",
    "                    bnd5 = np.copy(bnd[5])\n",
    "                    err5, i5 = 1 + Err[5], 0\n",
    "                    while np.max(np.abs(err5))>Err[5] and i5<I[5]:\n",
    "                        ϕ = (bnd5[0] + bnd5[1]) / 2                    \n",
    "\n",
    "                        bnd6 = np.copy(bnd[6])\n",
    "                        err6, i6 = 1 + Err[6], 0\n",
    "                        while np.max(np.abs(err6))>Err[6] and i6<I[6]:\n",
    "                            μ_a_ng = (bnd6[0] + bnd6[1]) / 2\n",
    "                            μ_a_ps = np.array([μ_a_ng, μ_a_g, μ_a_ng, μ_a_g]).reshape(2,2)\n",
    "\n",
    "                            # Solve model given parameter values\n",
    "                            bh = BlandinHerrington(λsp=λsp, μ_a_ps=μ_a_ps, loc_ξ_0=loc_ξ_0, ϕ=ϕ, ω_g=ω_g, α=α, ψ=ψ, ε=ε, σ=σ, σ_a=σ_a, ζ=ζ, σ_H=σ_H, NH=NH, NsdH=NsdH, scale_ξ=scale_ξ, θm=θm, ρ=ρ, path=path)\n",
    "                            d_ps, d_agg, d_agg_sd, prob_a, hh, reg = run_parametrized_model(bh, path_data)\n",
    "\n",
    "                            # Evaluate target 6 and adjust bnd5\n",
    "                            err6 = d_ps['hh'][0, 0] - mn_hh_ps[0, 0]\n",
    "                            err6 = np.nan_to_num(err6)\n",
    "                            bnd6[0] = np.where(err6>Err[6], bnd6[0], μ_a_ng)\n",
    "                            bnd6[1] = np.where(err6>=-Err[6], μ_a_ng, bnd6[1])                        \n",
    "                            i6 += 1 \n",
    "\n",
    "                        # Evaluate target 5 and adjust bnd5\n",
    "                        err5 = d_ps['hh'][1, 0] - mn_hh_ps[1, 0]\n",
    "                        err5 = np.nan_to_num(err5)\n",
    "                        bnd5[0] = np.where(err5>Err[5], bnd5[0], ϕ)\n",
    "                        bnd5[1] = np.where(err5>=-Err[5], ϕ, bnd5[1])                        \n",
    "                        i5 += 1                         \n",
    "                    \n",
    "                    while np.abs(err4)>Err[4] and i4<I[4]:\n",
    "                        μ_a_g = (bnd4[0] + bnd4[1]) / 2\n",
    "                        μ_a_ps = np.array([μ_a_ng, μ_a_g, μ_a_ng, μ_a_g]).reshape(2,2)\n",
    "                        \n",
    "                        # Solve model given parameter values\n",
    "                        bh = BlandinHerrington(λsp=λsp, μ_a_ps=μ_a_ps, loc_ξ_0=loc_ξ_0, ϕ=ϕ, ω_g=ω_g, α=α, ψ=ψ, ε=ε, σ=σ, σ_a=σ_a, ζ=ζ, σ_H=σ_H, NH=NH, NsdH=NsdH, scale_ξ=scale_ξ, θm=θm, ρ=ρ, path=path)\n",
    "                        d_ps, d_agg, d_agg_sd, prob_a, hh, reg = run_parametrized_model(bh, path_data)\n",
    "\n",
    "                        # Evaluate target 4 and adjust bnd4 without readjusting ϕ or μ_a_ng\n",
    "                        err4 = d_ps['hh'][1, 1] - mn_hh_ps[1, 1] - 1\n",
    "                        bnd4[0] = bnd4[0] * (err4>=-Err[4]) + μ_a_g * (err4<-Err[4])\n",
    "                        bnd4[1] = μ_a_g * (err4>Err[4]) + bnd4[1] * (err4<=Err[4])\n",
    "                        i4 += 1                        \n",
    "\n",
    "                    # Evaluate target 3 and adjust bnd3\n",
    "                    err3 = d_agg['sh_a'] - share_a\n",
    "                    bnd3[0] = loc_ξ_0 * (err3>=-Err[3]) + bnd3[0] * (err3<-Err[3])\n",
    "                    bnd3[1] = bnd3[1] * (err3>Err[3]) + loc_ξ_0 * (err3<=Err[3])\n",
    "                    i3 += 1\n",
    "\n",
    "                # Evaluate target 2 and adjust bnd2\n",
    "                err2 = np.exp(d_agg['leph_g']) / np.exp(d_agg['leph_na']) - mn_prem\n",
    "                bnd2[0] = bnd2[0] * (err2>Err[2]) + ω_g * (err2<=Err[2])\n",
    "                bnd2[1] = ω_g * (err2>=-Err[2]) + bnd2[1] * (err2<-Err[2])  \n",
    "                i2 += 1\n",
    "\n",
    "            # Evaluate target 1 and adjust bnd1\n",
    "            err1 = d_agg['i'] - mn_i\n",
    "            bnd1[0] = bnd1[0] * (err1>Err[1]) + α * (err1<=Err[1])\n",
    "            bnd1[1] = α * (err1>=-Err[1]) + bnd1[1] * (err1<-Err[1])        \n",
    "            i1 += 1\n",
    "            \n",
    "        # Evaluate target 0 and adjust bnd0\n",
    "        err0 = d_agg['m'] - mn_m - 3\n",
    "        bnd0[0] = bnd0[0] * (err0>Err[0]) + θm * (err0<=Err[0])\n",
    "        bnd0[1] = θm * (err0>=-Err[0]) + bnd0[1] * (err0<-Err[0])        \n",
    "        i0 += 1\n",
    "    \n",
    "    # re-order output calibration summary for output to correspond with paper table\n",
    "    descr =   ['Leisure utility weight', 'Parent altruism', 'CES weight of m', 'SD of parent human capital', 'College wage premium', 'Mean of taste shock', 'SD of taste shock', 'SD of idiosyncratic ability', 'Mean ability (non-college)', 'Mean ability (college)', 'Returns to scale', 'Exponent on H']\n",
    "    params =  {0: 'psi',      1: 'alpha',    2: 'theta_m',  3: 'sigma_H',         4: 'omega_g / omega_ng',                               5: 'mu_zeta',     6: 'sigma_xi',        7: 'sigma_a',            8: 'mu_a_ng',                  9: 'mu_a_g',                   10: 'phi',            11: 'eta'}\n",
    "    values =  {0: bh.ψ,       1: α,          2: θm,         3: bh.σ_H,            4: 1 + ω_g,                                            5: loc_ξ_0,       6: bh.scale_ξ,        7: bh.σ_a,               8: μ_a_ng,                     9: μ_a_g,                      10: ϕ,                11: bh.ζ }\n",
    "    moments = ['Mean labor supply of adult children', 'Mean time investment', 'Mean market investment', 'Variance of log parent earnings', 'Coll/No Coll earn ratio', 'Aggregate attendance rate', 'corr(SAT, attendance)', 'SD of SAT within family types', 'Mean SAT, 2L', 'Mean SAT, 2H', 'Mean SAT, 1L', 'Coefficients in collete completion reg; See Table 5.']\n",
    "    model =   {0: np.round(d_agg['n'], 2), 1: np.round(d_agg['i'], 3), 2: np.round(d_agg['m']), 3: np.round(d_agg_sd['lE']**2, 2), 4: np.round(np.exp(d_agg['leph_g']) / np.exp(d_agg['leph_na']), 2), 5: np.round(d_agg['sh_a'], 2), 6: np.round(corr_h_attend(bh), 2), 7: np.round(np.std(hh)), 8: np.round(d_ps['hh'][1, 0]), 9: np.round(d_ps['hh'][1, 1]), 10: np.round(d_ps['hh'][0, 0]), 11: ' ' }\n",
    "    data =    {0: 0.40,       1: mn_i,       2: mn_m,       3: 0.554,             4: mn_prem,                                            5: share_a,       6: 0.40,              7: 91,                   8: mn_hh_ps[1, 0],             9: mn_hh_ps[1, 1],             10: mn_hh_ps[0, 0],   11: 0.09 }    \n",
    "    \n",
    "    # output calibration results\n",
    "    if maketab==True:\n",
    "        fpath = '../output/tables/table4.csv'\n",
    "        rows = np.array([list(params.values()),\n",
    "                descr,\n",
    "                list(np.round(list(values.values()), 2)),\n",
    "                moments,\n",
    "                list(np.round(list(data.values()), 2)),\n",
    "                list(model.values())\n",
    "               ]).T\n",
    "        with open(fpath, 'w', newline='') as f:\n",
    "            pen = csv.writer(f)\n",
    "            pen.writerow(['Parameter', 'Description', 'Value', 'Target Moment', 'Data', 'Model'])\n",
    "            for row in rows:\n",
    "                pen.writerow(list(row))\n",
    "\n",
    "    return bh\n",
    "\n",
    "def ctrf_alt_calib(nP, nS, bh, attend_target=np.array([[0.5523-0.070, 0.6724-0.273], [0.6187-0.155, 0.7590-0.020]])):\n",
    "    \n",
    "    ### Initialize parameters for calibration\n",
    "    # Parameter order: θm, α, ω_g, loc_ξ_0, μ_a_g, ϕ, μ_a_ng\n",
    "    # Target order: mn_m, mn_i, mn_prem, share_a, mn_hh_2h, mn_hh_2l, mn_hh_1l\n",
    "    Err = 0.0005\n",
    "    I = 20\n",
    "\n",
    "    # calibrate value of loc_ξ_0\n",
    "    \n",
    "    bnd = [-2.0, 1.0]\n",
    "    err, i = 1 + Err, 0\n",
    "    while np.abs(err)>Err and i<I:\n",
    "        loc_ξ_0 = (bnd[0] + bnd[1]) / 2\n",
    "\n",
    "        # Solve model given parameter values\n",
    "        bh.loc_ξ_0 = loc_ξ_0\n",
    "        bh.loc_ξ = bh.loc_ξ_0 - bh.scale_ξ * 0.557\n",
    "        d_ps, d_agg, d_agg_sd, prob_a, reg_gradprob_results = run_counterfactual(bh, path_d1995)\n",
    "\n",
    "        # Evaluate target 3 and adjust bnd3\n",
    "        err = d_ps['sh_a'][nP, nS] - attend_target[nP, nS]\n",
    "        \n",
    "        bnd[0] = loc_ξ_0 * (err>=-Err) + bnd[0] * (err<-Err)\n",
    "        bnd[1] = bnd[1] * (err>Err) + loc_ξ_0 * (err<=Err)\n",
    "        i += 1\n",
    "\n",
    "    return bh\n",
    "\n",
    "def shift_share_decomp(bh_early, bh_late):\n",
    "    \n",
    "    # Read stats from baseline and counterfactual models\n",
    "    df0 = pd.read_csv(bh_early.path + 'statsvsdata.csv', skiprows=1)\n",
    "    df1 = pd.read_csv(bh_late.path + 'statsvsdata.csv', skiprows=1)\n",
    "    λ0 = np.array(df0.iloc[0, 2:6]).astype(float)\n",
    "    λ0 = λ0 / np.sum(λ0)\n",
    "    λ1 = np.array(df1.iloc[0, 2:6]).astype(float)\n",
    "    λ1 = λ1 / np.sum(λ1)\n",
    "    g_d = np.array(df0.iloc[5, 2:6]).astype(float)\n",
    "    g_m = np.array(df0.iloc[13, 2:6]).astype(float)\n",
    "    \n",
    "    # compute baseline agg graduation\n",
    "    g_d_agg0 = float(df0.iloc[5, 1])\n",
    "    g_m_agg0 = float(df0.iloc[13, 1])\n",
    "    g_d_agg1 = np.sum(λ1 * g_d)\n",
    "    g_m_agg1 = np.sum(λ1 * g_m)\n",
    "    \n",
    "    # Write to new csv the difference btween counterfactual and baseline\n",
    "    fpath = '../output/intext/intext_sec_V_C_shiftshare.csv'\n",
    "    with open(fpath, 'w', newline='') as f:\n",
    "        pen = csv.writer(f)\n",
    "        pen.writerow(['share_effect_d', 'share_effect_m'])\n",
    "        pen.writerow([g_d_agg1 - g_d_agg0, g_m_agg1 - g_m_agg0])\n",
    "        \n",
    "def corr_h_attend(bh, Nsim=10_000):\n",
    "    \"\"\"\n",
    "    compute correlation between child human capital and college attendance\n",
    "    \"\"\"\n",
    "    shape = (bh.NP, bh.NS, bh.NH, bh.Na, Nsim)\n",
    "    attend, hh = np.zeros(shape), np.zeros(shape)\n",
    "\n",
    "    prob_a, v2, v2_na, v2_a, y2_na, y2_a_ng, y2_a_g, c_na, c_a_ng, c_a_g, n_na, n_a_ng, n_a_g = bh.solve_c_2(h=bh.gridh, T=0)\n",
    "    V2, Y2, C2, N2 = bh.solve_p_2()\n",
    "    [mC, mN, mKK, mi, mm, mhh, mattend, mgrad, mn, mn_na, mn_ng, mn_g] = bh.solve_p_1(prob_a, v2, V2, C2, n_na, n_a_ng, n_a_g)\n",
    "\n",
    "    for nP in range(bh.NP):\n",
    "        for nS in range(bh.NS):\n",
    "            for nH in range(bh.NH):\n",
    "                for na in range(bh.Na):\n",
    "                    for nsim in range(Nsim):\n",
    "                        attend[nP, nS, nH, na, nsim] = np.random.binomial(n=1, p=mattend[nP, nS, nH, na])\n",
    "                        hh[nP, nS, nH, na, nsim] = mhh[nP, nS, nH, na]\n",
    "    \n",
    "    return np.corrcoef(hh.flatten(), attend.flatten())[1, 0]\n",
    "\n",
    "def maketables(datapath='', path=''):\n",
    "\n",
    "    # table 6: counterfactual changes in investment, preparation, and college attainment\n",
    "    dfm = pd.read_csv(datapath + '0/ctrf/stats_change.csv')\n",
    "    dfi = pd.read_csv(datapath + '0/ctrf/investonly/stats_change.csv')\n",
    "    rows = [[' ', ' ', ' ', 'Counterfactuals']]\n",
    "    rows.append(['Variable', 'Family Type', 'Data', 'Main', 'Investment Only'])\n",
    "    col_d = [0.018, 0.084, 0.111, 0.106, 0.070, 0.155, 0.020, 0.127, 106, 43, 429, 208, 1.75, 3.10, 4.41, 3.09, 13.3, 7.1]\n",
    "    types = ['1L', '2L', '2H', 'Agg, Mn']\n",
    "    vrbls = [7, 6, 4, 3]\n",
    "    vlbls = ['Delta Completion share', 'Delta Attendance share', 'Delta Mean Market Investments', 'Delta Mean Time Investments', 'Delta Mean Human Capital Gap']\n",
    "    rnd = {7: 3, 6: 3, 4: 0, 3: 2}\n",
    "    col_v = [[vlbl, ' ', ' ', ' '] for vlbl in vlbls]\n",
    "    col_v = [row for v in col_v for row in v][:-2]\n",
    "    col_f = [f[:3] for nv in range(len(vrbls)) for f in types] + ['2L-1L', '2H-1L']\n",
    "    col_m = [np.round(dfm[f][v], rnd[v]) for v in vrbls for f in types]\n",
    "    col_m.extend(np.round([dfm['2L'][5] - dfm['1L'][5], dfm['2H'][5] - dfm['1L'][5]], 1))\n",
    "    col_i = [np.round(dfi[f][v], rnd[v]) for v in vrbls for f in types]\n",
    "    col_i.extend(np.round([dfi['2L'][5] - dfi['1L'][5], dfi['2H'][5] - dfi['1L'][5]], 1))\n",
    "    cols = np.array([col_v, col_f, col_d, col_m, col_i]).T\n",
    "    rows.extend(list(cols))\n",
    "    fpath = path + 'tables/table6.csv'\n",
    "    with open(fpath, 'w', newline='') as f:\n",
    "        pen = csv.writer(f)\n",
    "        for row in rows:\n",
    "            pen.writerow(row)\n",
    "\n",
    "    # table c1: alternative counterfactual changes in investment, preparation, and college attainment\n",
    "    rows = [[' ', ' ', ' ', 'Counterfactuals']]\n",
    "    rows.append(['Variable', 'Family Type', 'Data', 'Main', 'Alternative'])\n",
    "    dfcal_level = pd.read_csv(datapath + '0/stats.csv')\n",
    "    dfalt_level = {'1L': pd.read_csv(datapath + '0/ctrf/ctrf_alt/00/stats.csv'),\n",
    "                   '2L': pd.read_csv(datapath + '0/ctrf/ctrf_alt/10/stats.csv'),\n",
    "                   '1H': pd.read_csv(datapath + '0/ctrf/ctrf_alt/01/stats.csv'),\n",
    "                   '2H': pd.read_csv(datapath + '0/ctrf/ctrf_alt/11/stats.csv')\n",
    "                  }\n",
    "    aggs = [np.round(dfcal_level['Agg, Mn'][v] - sum([dfalt_level[f][f][v] * dfalt_level[f][f][0] for f in dfalt_level.keys()]), rnd[v]) for nv, v in enumerate(vrbls)]\n",
    "    dfalt = {'1L': pd.read_csv(datapath + '0/ctrf/ctrf_alt/00/stats_change.csv'),\n",
    "             '2L': pd.read_csv(datapath + '0/ctrf/ctrf_alt/10/stats_change.csv'),\n",
    "             '2H': pd.read_csv(datapath + '0/ctrf/ctrf_alt/11/stats_change.csv')\n",
    "            }\n",
    "    dfalt['Agg, Mn'] = dfalt['1L']\n",
    "    col_alt = [np.round(dfalt[f][f][v], rnd[v]) for v in vrbls for f in types]\n",
    "    col_alt[3], col_alt[7], col_alt[11], col_alt[15] = aggs\n",
    "    col_alt.extend(np.round([dfalt['2L']['2L'][5] - dfalt['1L']['1L'][5], dfalt['2H']['2H'][5] - dfalt['1L']['1L'][5]], 1))\n",
    "    cols = np.array([col_v, col_f, col_d, col_m, col_alt]).T\n",
    "    rows.extend(list(cols))\n",
    "    fpath = path + 'tables/tablec1.csv'\n",
    "    with open(fpath, 'w', newline='') as f:\n",
    "        pen = csv.writer(f)\n",
    "        for row in rows:\n",
    "            pen.writerow(row)\n",
    "\n",
    "    # table c2: changes in investment and completion for different substitution elasticities\n",
    "    vrbls = [7, 4, 3]\n",
    "    vlbls = ['Delta Completion share', 'Delta Mean Market Investments', 'Delta Mean Time Investments']\n",
    "    rows = [['Variable', 'Family Type', 'rho=-0.9', 'rho-->0 (Baseline)', 'rho=0.7']]\n",
    "    col_v = [[vlbl, ' ', ' ', ' '] for vlbl in vlbls]\n",
    "    col_v = [row for v in col_v for row in v]\n",
    "    col_f = [f[:3] for nv in range(len(vrbls)) for f in types]\n",
    "    col_m = [np.round(dfm[f][v], rnd[v]) for v in vrbls for f in types]\n",
    "    dfsubs = pd.read_csv(datapath + '1/ctrf/stats_change.csv')\n",
    "    col_subs = [np.round(dfsubs[f][v], rnd[v]) for v in vrbls for f in types]\n",
    "    dfcomp = pd.read_csv(datapath + '2/ctrf/stats_change.csv')\n",
    "    col_comp = [np.round(dfcomp[f][v], rnd[v]) for v in vrbls for f in types]\n",
    "    cols = np.array([col_v, col_f, col_comp, col_m, col_subs]).T\n",
    "    rows.extend(list(cols))\n",
    "    fpath = path + 'tables/tablec2.csv'\n",
    "    with open(fpath, 'w', newline='') as f:\n",
    "        pen = csv.writer(f)\n",
    "        for row in rows:\n",
    "            pen.writerow(row)\n",
    "\n",
    "    # in-text numbers for section V.B\n",
    "    df = pd.read_csv(datapath + '0/ctrf/stats_change.csv')\n",
    "    rows = [['Family Type', '1L', '2L', '2H']]\n",
    "    rows.append(['Delta human capital', df['1L'][5], df['2L'][5], df['2H'][5]])\n",
    "    fpath = path + 'intext/intext_sec_V_B_changehc.csv'\n",
    "    with open(fpath, 'w', newline='') as f:\n",
    "        pen = csv.writer(f)\n",
    "        for row in rows:\n",
    "            pen.writerow(row)\n",
    "    \n",
    "    \n",
    "    # in-text numbers for section V.D\n",
    "    df = {}\n",
    "    df[0] = pd.read_csv(datapath + '0/ctrf/stats_change.csv')\n",
    "    df[1] = pd.read_csv(datapath + '0/ctrf/decomp_1/stats_change.csv')\n",
    "    df[2] = pd.read_csv(datapath + '0/ctrf/decomp_2/stats_change.csv')\n",
    "    df[3] = pd.read_csv(datapath + '0/ctrf/decomp_3/stats_change.csv')\n",
    "    rows = [['Unit', 'Delta sd: overall', 'Delta sd: premium', 'Delta sd: composition', 'Delta sd: preparation']]\n",
    "    rows.append(['Parent', df[0]['Agg, SD'][1], df[1]['Agg, SD'][1], df[2]['Agg, SD'][1], ' '])\n",
    "    rows.append(['Child', df[0]['Agg, SD'][12], df[2]['Agg, SD'][12], ' ', df[3]['Agg, SD'][12]])\n",
    "    fpath = path + 'intext/intext_sec_V_D_inequality.csv'\n",
    "    with open(fpath, 'w', newline='') as f:\n",
    "        pen = csv.writer(f)\n",
    "        for row in rows:\n",
    "            pen.writerow(row)\n",
    "\n",
    "    # table 7: policy experiments: average effects among 1L children\n",
    "    df = {}\n",
    "    df[0] = pd.read_csv(datapath + '0/stats.csv')\n",
    "    df[1] = pd.read_csv(datapath + '0/transfer_tuition/stats.csv')\n",
    "    df[2] = pd.read_csv(datapath + '0/transfer/stats.csv')\n",
    "    df[3] = pd.read_csv(datapath + '0/transfer_m/stats.csv')\n",
    "    df[4] = pd.read_csv(datapath + '0/subsidy_m/stats.csv')\n",
    "    df[5] = pd.read_csv(datapath + '0/subsidy_i/stats.csv')\n",
    "    rows = np.zeros([4, 5])\n",
    "    vrbls = [5, 6, 7, 13]\n",
    "    vlbls = ['Delta h (SAT points)', 'Delta attendance (pp)', 'Delta completion (pp)', 'Delta mean lifetime earnings net of tuition (%)']\n",
    "    scale = {5: 1, 6: 100, 7: 100, 13: 100}\n",
    "    for m in range(1, 6):\n",
    "        for nv, v in enumerate(vrbls):\n",
    "            rows[nv, m - 1] = np.round(scale[v] * (df[m]['1L'][v] - df[0]['1L'][v]), 1)\n",
    "    fpath = path + 'tables/table7.csv'\n",
    "    with open(fpath, 'w', newline='') as f:\n",
    "        pen = csv.writer(f)\n",
    "        pen.writerow(['Change relative to baseline model', 'Tuition Subsidy', 'Unrestricted Transfer', 'Restricted Transfer', 'Subsidy for m', 'Subsidy for i'])\n",
    "        for row, vlbl in zip(rows, vlbls):\n",
    "            pen.writerow([vlbl] + list(row))\n",
    "\n",
    "########################################################################################\n",
    "\n",
    "##########################\n",
    "##  Create directories  ##\n",
    "##########################\n",
    "\n",
    "from pathlib import Path\n",
    "for nρ in range(3):\n",
    "    s = str(nρ)\n",
    "    \n",
    "    for f in ['00', '01', '10', '11']:\n",
    "        \n",
    "        Path('../intermediate/' + s + '/ctrf/ctrf_alt/' + f).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    for f in ['decomp_1', 'decomp_2', 'decomp_3', 'investonly']:\n",
    "        \n",
    "        Path('../intermediate/' + s + '/ctrf/' + f).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    for f in ['subsidy_i', 'subsidy_m', 'transfer', 'transfer_m', 'transfer_tuition']:\n",
    "        \n",
    "        Path('../intermediate/' + s + '/' + f).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "            \n",
    "########################################################################################\n",
    "\n",
    "#########################\n",
    "##  Calibrate to 2015  ##\n",
    "#########################\n",
    "\n",
    "# Set empirical targets for calibration of baseline model\n",
    "mn_m, mn_i, mn_prem, sd_hh = 488, 0.055, 1.80, 85, \n",
    "share_a, share_a_ps = 0.632, np.array([0.45, 0.77, 0.64, 0.84]).reshape(2, 2)\n",
    "mn_hh, mn_hh_ps = 467.7, np.array([422, 484, 449, 524]).reshape(2, 2)\n",
    "estD = [.092, -.076, .107, .318]\n",
    "path_d1995, path_d2015 = '../data/moments_1995_adj_forleis.csv', '../data/moments_2015_adj_forleis.csv'\n",
    "\n",
    "# parameters for baseline model\n",
    "λsp = np.array([0.32, 0.04, 0.40, 0.24]).reshape(2,2)\n",
    "scale_ξ = 0.40\n",
    "σ_a = 0.175\n",
    "ζ = 0.098\n",
    "σ_H, NH, NsdH = 0.55, 5, 3\n",
    "ε, ψ, σ = 1.01, 1.65, 2.00001\n",
    "\n",
    "for nρ, ρ in enumerate([0.01, 0.7, -0.9]):\n",
    "    print('')\n",
    "    print('nρ = ', nρ, ', ρ = ', np.round(ρ, 2))\n",
    "    print('')\n",
    "    maketab = True if nρ==0 else False\n",
    "    \n",
    "    ###########################################################\n",
    "    ##    baseline calibration \n",
    "    ###########################################################\n",
    "    bh = calibrate(mn_m, mn_i, mn_prem, sd_hh, share_a, share_a_ps, mn_hh, mn_hh_ps, λsp, σ=σ, ε=ε, ψ=ψ, ρ=ρ, σ_a=σ_a, ζ=ζ, σ_H=σ_H, NH=NH, NsdH=NsdH, scale_ξ=scale_ξ, maketab=maketab, path='../intermediate/{}/'.format(nρ), path_data=path_d2015)\n",
    "    μ_a_ps, loc_ξ_0, σ_a, ω_g, α, ψ, ε = bh.μ_a_ps, bh.loc_ξ_0, bh.σ_a, bh.ω_g, bh.α, bh.ψ, bh.ε\n",
    "    ϕ, scale_ξ, θm, ρ = bh.ϕ, bh.scale_ξ, bh.θm, bh.ρ\n",
    "    τ_m_ps = bh.τ_m_ps\n",
    "    bh = BlandinHerrington(λsp=λsp, ε=ε, ψ=ψ, ω_g=ω_g, α=α, ϕ=ϕ, loc_ξ_0=loc_ξ_0, μ_a_ps=μ_a_ps, σ=σ, σ_a=σ_a, ζ=ζ, σ_H=σ_H, NH=NH, NsdH=NsdH, scale_ξ=scale_ξ, θm=θm, ρ=ρ, path='../intermediate/{}/'.format(nρ))   \n",
    "    \n",
    "    # Compute statistics for calibrated (baseline) model\n",
    "    d_ps, d_agg, d_agg_sd, prob_a_fixed, hh, reg = run_parametrized_model(bh, path_d2015, output=True)\n",
    "    \n",
    "    if maketab==True:\n",
    "        bh.maketab5(reg)\n",
    "    \n",
    "    ###########################################################\n",
    "    ##    main and investment-only counterfactuals  \n",
    "    ###########################################################\n",
    "    \n",
    "    # Set exogenous parameters for main counterfactual\n",
    "    λsp_2 = np.array([0.28, 0.02, 0.59, 0.11]).reshape(2,2) \n",
    "    ω_g_2 = 0.41 \n",
    "    τ_m_2 = 4 * np.array([3_345, 5_657, 2_534, 4_846]).reshape(2,2)\n",
    "\n",
    "    # Compute statistics for main counterfactual\n",
    "    bh_2 = BlandinHerrington(λsp=λsp_2, ε=ε, ψ=ψ, τ_m_ps=τ_m_2, ω_g=ω_g_2, α=α, ϕ=ϕ, σ=σ, loc_ξ_0=loc_ξ_0, μ_a_ps=μ_a_ps, σ_a=σ_a, ζ=ζ, σ_H=σ_H, NH=NH, NsdH=NsdH, scale_ξ=scale_ξ, θm=θm, ρ=ρ, path='../intermediate/{}/ctrf/'.format(nρ))\n",
    "    d_ps_2, d_agg_2, d_agg_sd_2, prob_a_2, reg_gradprob_results = run_counterfactual(bh_2, path_d1995)\n",
    "    bh_2.output_results(d_ps_2, d_agg_2, d_agg_sd_2, prob_a_2, reg_gradprob_results, path_d1995)\n",
    "    compare_baseline_ctrf(bh_early=bh_2, bh_late=bh) # Compute change in statistics between counterfactual and calibrated\n",
    "    shift_share_decomp(bh_early=bh_2, bh_late=bh)\n",
    "        \n",
    "    # Compute statistics for investment-only counterfactual\n",
    "    bh_2.path = bh_2.path + 'investonly/'\n",
    "    d_ps_2i, d_agg_2i, d_agg_sd_2i, prob_a_2i, reg_gradprob_results = run_counterfactual(bh_2, path_data=path_d1995, invonly=True, prob_a_fixed=prob_a_fixed)\n",
    "    bh_2.output_results(d_ps_2i, d_agg_2i, d_agg_sd_2i, prob_a_2i, reg_gradprob_results, path_d1995)\n",
    "    compare_baseline_ctrf(bh_early=bh_2, bh_late=bh) # Compute change in statistics between counterfactual and calibrated\n",
    "    \n",
    "    \n",
    "    ###########################################################\n",
    "    ##    inequality decomposition counterfactuals  \n",
    "    ###########################################################   \n",
    "    \n",
    "    # role of college premium\n",
    "    path_ctrf = '../intermediate/0/ctrf/decomp_1/'\n",
    "    bh_ctrf = decompose_ineq(bh, ω_g_2, λsp, path_ctrf, path_d1995)\n",
    "    compare_baseline_ctrf(bh_early=bh_ctrf, bh_late=bh) \n",
    "\n",
    "    # role of family composition\n",
    "    path_ctrf = '../intermediate/0/ctrf/decomp_2/'\n",
    "    bh_ctrf = decompose_ineq(bh, ω_g, λsp_2, path_ctrf, path_d1995)\n",
    "    compare_baseline_ctrf(bh_early=bh_ctrf, bh_late=bh)  \n",
    "\n",
    "    # role of changing preparedness\n",
    "    path_ctrf = '../intermediate/0/ctrf/decomp_3/'\n",
    "    bh_ctrf = decompose_ineq(bh_2, ω_g, λsp, path_ctrf, path_d1995)\n",
    "    compare_baseline_ctrf(bh_early=bh_ctrf, bh_late=bh) \n",
    "    \n",
    "    \n",
    "    ###########################################################\n",
    "    ##    alternative counterfactual: \"target attendance\"    \n",
    "    ###########################################################\n",
    "\n",
    "    # iterate through family types\n",
    "    for nP in range(2):\n",
    "        for nS in range(2):\n",
    "\n",
    "            # calibrate new shock mean for type\n",
    "            bh_2 = BlandinHerrington(λsp=λsp_2, ε=ε, ψ=ψ, τ_m_ps=τ_m_2, ω_g=ω_g_2, α=α, ϕ=ϕ, σ=σ, loc_ξ_0=loc_ξ_0, μ_a_ps=μ_a_ps, σ_a=σ_a, ζ=ζ, σ_H=σ_H, NH=NH, NsdH=NsdH, scale_ξ=scale_ξ, θm=θm, ρ=ρ, path='../intermediate/{}/ctrf/'.format(nρ))\n",
    "            bh_2alt = ctrf_alt_calib(nP, nS, bh_2)\n",
    "            bh_2alt.path='../intermediate/{}/ctrf/ctrf_alt/{}{}/'.format(nρ, nP, nS)\n",
    "\n",
    "            # Compute statistics for main counterfactual\n",
    "            d_ps_2alt, d_agg_2alt, d_agg_sd_2alt, prob_a_2alt, reg_gradprob_results = run_counterfactual(bh_2alt, path_d1995)\n",
    "            bh_2alt.output_results(d_ps_2alt, d_agg_2alt, d_agg_sd_2alt, prob_a_2alt, reg_gradprob_results, path_d1995)\n",
    "\n",
    "            # Compute change in statistics between counterfactual and calibrated\n",
    "            compare_baseline_ctrf(bh_early=bh_2alt, bh_late=bh)    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ###########################################################\n",
    "    ##    policy counterfactuals targeted to 1L families  \n",
    "    ###########################################################\n",
    "    \n",
    "    # Compute tuition subsidy\n",
    "    bh_3 = deepcopy(bh)\n",
    "    bh_3.path='../intermediate/{}/transfer_tuition/'.format(nρ)\n",
    "    Tτ = counterfactual_tuitionsubsidy(bh_3, path_data=path_d2015, attend_2L=.605, minTτ=τ_m_ps[0, 0], maxTτ=τ_m_ps[0, 0], NTτ=1)\n",
    "    \n",
    "    # Compute i subsidy\n",
    "    bh_4 = deepcopy(bh)\n",
    "    bh_4.path='../intermediate/{}/subsidy_i/'.format(nρ)\n",
    "    counterfactual_isubsidy(bh_4, path_data=path_d2015, T=Tτ * .571)        \n",
    "    \n",
    "    # Compute m subsidy\n",
    "    bh_5 = deepcopy(bh)\n",
    "    bh_5.path='../intermediate/{}/subsidy_m/'.format(nρ)\n",
    "    counterfactual_msubsidy(bh_5, path_data=path_d2015, T=Tτ * .571)  \n",
    "    \n",
    "    # Compute m transfer\n",
    "    bh_6 = deepcopy(bh)\n",
    "    bh_6.path='../intermediate/{}/transfer_m/'.format(nρ)\n",
    "    counterfactual_mtransfer(bh_6, path_data=path_d2015, attend_2L=.605, minTm=Tτ * .571, maxTm=Tτ * .571, NTm=1)        \n",
    "    \n",
    "    # Compute m transfer\n",
    "    bh_7 = deepcopy(bh)\n",
    "    bh_7.path='../intermediate/{}/transfer/'.format(nρ)\n",
    "    counterfactual_transfer(bh_7, path_data=path_d2015, T=Tτ * .571) \n",
    "\n",
    "maketables(datapath='../intermediate/', path='../output/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
